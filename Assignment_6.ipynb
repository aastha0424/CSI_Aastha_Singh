{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "069a7f83",
   "metadata": {},
   "source": [
    "To train multiple machine learning models, evaluate their performance using metrics (accuracy, precision, recall, F1-score), and perform hyperparameter tuning (using GridSearchCV and RandomizedSearchCV), here's a complete pipeline in Python using scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0b4fa",
   "metadata": {},
   "source": [
    "‚úÖ Step-by-step Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f110ed",
   "metadata": {},
   "source": [
    "üîß 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9378fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604f065",
   "metadata": {},
   "source": [
    "üìä 2. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac39430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Use the breast cancer dataset from sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c736d9",
   "metadata": {},
   "source": [
    "‚öôÔ∏è 3. Define Models and Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1680a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(max_iter=10000),\n",
    "        \"params\": {\n",
    "            \"model__C\": [0.1, 1, 10],\n",
    "            \"model__penalty\": [\"l2\"],\n",
    "            \"model__solver\": [\"lbfgs\"]\n",
    "        }\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"model__n_estimators\": [50, 100, 200],\n",
    "            \"model__max_depth\": [None, 10, 20]\n",
    "        }\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"model\": SVC(),\n",
    "        \"params\": {\n",
    "            \"model__C\": [0.1, 1, 10],\n",
    "            \"model__kernel\": [\"linear\", \"rbf\"]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "        \"params\": {\n",
    "            \"model__n_estimators\": [50, 100],\n",
    "            \"model__learning_rate\": [0.01, 0.1],\n",
    "            \"model__max_depth\": [3, 5]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc5a1d",
   "metadata": {},
   "source": [
    "üîç 4. Train Models with GridSearchCV and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3683cd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Best Parameters: {'model__C': 1, 'model__penalty': 'l2', 'model__solver': 'lbfgs'}\n",
      "Accuracy: 0.9737 | Precision: 0.9722 | Recall: 0.9859 | F1-score: 0.9790\n",
      "\n",
      "Training Random Forest...\n",
      "Best Parameters: {'model__max_depth': 20, 'model__n_estimators': 100}\n",
      "Accuracy: 0.9561 | Precision: 0.9583 | Recall: 0.9718 | F1-score: 0.9650\n",
      "\n",
      "Training SVC...\n",
      "Best Parameters: {'model__C': 0.1, 'model__kernel': 'linear'}\n",
      "Accuracy: 0.9825 | Precision: 0.9726 | Recall: 1.0000 | F1-score: 0.9861\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2004a\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:25:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 50}\n",
      "Accuracy: 0.9561 | Precision: 0.9583 | Recall: 0.9718 | F1-score: 0.9650\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model_name, mp in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', mp['model'])\n",
    "    ])\n",
    "\n",
    "    grid = GridSearchCV(pipe, mp['params'], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Best Parameters: {grid.best_params_}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Best Params\": grid.best_params_,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c5809",
   "metadata": {},
   "source": [
    "üìà 5. Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20336daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Summary:\n",
      "                 Model                                        Best Params  \\\n",
      "2                  SVC       {'model__C': 0.1, 'model__kernel': 'linear'}   \n",
      "0  Logistic Regression  {'model__C': 1, 'model__penalty': 'l2', 'model...   \n",
      "1        Random Forest  {'model__max_depth': 20, 'model__n_estimators'...   \n",
      "3              XGBoost  {'model__learning_rate': 0.1, 'model__max_dept...   \n",
      "\n",
      "   Accuracy  Precision    Recall  F1 Score  \n",
      "2  0.982456   0.972603  1.000000  0.986111  \n",
      "0  0.973684   0.972222  0.985915  0.979021  \n",
      "1  0.956140   0.958333  0.971831  0.965035  \n",
      "3  0.956140   0.958333  0.971831  0.965035  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(results_df.sort_values(by=\"F1 Score\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc94b6cd",
   "metadata": {},
   "source": [
    "üîÅ Use RandomizedSearchCV Instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfbf3783",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(pipe, mp['params'], n_iter=10, cv=5, random_state=42, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc936a",
   "metadata": {},
   "source": [
    "üß† Observations\n",
    "\n",
    "1. ‚úÖ Support Vector Classifier (SVC) achieved the highest F1 Score (0.9861) and perfect Recall (1.0), making it the best model for this classification task.\n",
    "\n",
    "2. ‚úÖ Logistic Regression performed almost as well with high recall and precision, and is a simpler, more interpretable model.\n",
    "\n",
    "3. ‚ö†Ô∏è Random Forest and XGBoost showed similar performance, slightly lower than SVC and Logistic Regression. These models might still be preferred in more complex or larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1311bd0",
   "metadata": {},
   "source": [
    "üìå Final Recommendation\n",
    "\n",
    "1. Best Model: SVC with parameters C = 0.1, kernel = 'linear'\n",
    "This model should be selected for deployment based on current metrics, especially if Recall is critical (e.g., medical diagnosis).\n",
    "\n",
    "2. Alternative Consideration: If computational efficiency and interpretability are more important, Logistic Regression offers a strong trade-off."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
